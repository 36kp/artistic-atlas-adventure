{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../pickles/resized_images.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# import images from ../../Resources/resized_images.pkl file\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m images \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../../pickles/resized_images.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# import labels from ../../Resources/labels.pkl file\u001b[39;00m\n\u001b[0;32m      5\u001b[0m labels \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../pickles/labels.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../pickles/resized_images.pkl'"
     ]
    }
   ],
   "source": [
    "# import images from ../../Resources/resized_images.pkl file\n",
    "images = pickle.load(open(\"../../pickles/resized_images.pkl\", \"rb\"))\n",
    "\n",
    "# import labels from ../../Resources/labels.pkl file\n",
    "labels = pickle.load(open(\"../../pickles/labels.pkl\", \"rb\"))\n",
    "\n",
    "#show first image and its label\n",
    "print(f\"Label: {labels.iloc[0]}\")\n",
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform augmentation on one image\n",
    "# create a pixel array from the image\n",
    "image = images[0]\n",
    "image_pxl_array = np.array(image)\n",
    "\n",
    "#print pixel values\n",
    "print(image_pxl_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all images to a floating point numpy array for augmentation\n",
    "imgs_pxl_array = np.array(images).astype('float32')\n",
    "\n",
    "# Since pixel values are ranging from 0-255, normaize it by dividing by 255\n",
    "normalized_images = [img / 255 for img in imgs_pxl_array]\n",
    "\n",
    "# Print out the first image values\n",
    "print(normalized_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an image augmentation pipeline\n",
    "image_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomRotation(0.05),        # Random rotation (18 degrees)\n",
    "    tf.keras.layers.RandomZoom(0.25),            # Random zoom\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\")    # Random horizontal flip\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y arrays\n",
    "y = np.array(labels).reshape(-1, 1)\n",
    "\n",
    "X = np.array(normalized_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets with 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list for X and y augmentations\n",
    "X_train_aug = []\n",
    "y_train_aug = []\n",
    "\n",
    "# Loop through the entire X_train set\n",
    "for i in range(len(X_train)):\n",
    "    # Select the original image and its y label\n",
    "    img = X_train[i]\n",
    "    label = y_train[i]\n",
    "\n",
    "    # Ensure that the input data has the correct shape\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Add one more augmented for every original\n",
    "    # Create and append the image\n",
    "    X_train_aug.append(image_augmentation(img, training=True)[0].numpy())\n",
    "    # Append the original label\n",
    "    y_train_aug.append(label)\n",
    "\n",
    "# Print the length of the augmented images and the labels\n",
    "print(len(X_train_aug))\n",
    "print(len(y_train_aug))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the original and augmented images and labels\n",
    "X_train = np.concatenate((X_train, np.array(X_train_aug)))\n",
    "y_train = np.concatenate((y_train, np.array(y_train_aug)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False).fit(np.array(y_train).reshape(-1, 1))\n",
    "y_train_enc = y_encoder.transform(np.array(y_train).reshape(-1, 1))\n",
    "y_test_enc = y_encoder.transform(np.array(y_test).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X_train.shape, y_train_enc.shape, X_test.shape, y_test_enc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set ulimit to 12G to deal with large data export\n",
    "!ulimit -n 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the augmented images and labels in pickle files\n",
    "pickle.dump(y_train_enc, \n",
    "            open(\"../../pickles/y_train_aug.pkl\", \"wb\"), \n",
    "            protocol=pickle.HIGHEST_PROTOCOL)\n",
    "pickle.dump(X_train, \n",
    "            open(\"../../pickles/X_train_aug.pkl\", \"wb\"), \n",
    "            protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export test images and labels in pickle files\n",
    "pickle.dump(y_test_enc, \n",
    "            open(\"../../pickles/y_test.pkl\", \"wb\"), \n",
    "            protocol=pickle.HIGHEST_PROTOCOL)\n",
    "pickle.dump(X_test, \n",
    "            open(\"../../pickles/X_test.pkl\", \"wb\"), \n",
    "            protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
