{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import images from ../../Resources/resized_images.pkl file\n",
    "images = pickle.load(open(\"../../pickles/resized_images.pkl\", \"rb\"))\n",
    "\n",
    "# import labels from ../../Resources/labels.pkl file\n",
    "labels = pickle.load(open(\"../../pickles/labels.pkl\", \"rb\"))\n",
    "\n",
    "#show first image and its label\n",
    "print(f\"Label: {labels.iloc[0]}\")\n",
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform augmentation on one image\n",
    "# create a pixel array from the image\n",
    "image = images[0]\n",
    "image_pxl_array = np.array(image)\n",
    "\n",
    "#print pixel values\n",
    "print(image_pxl_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all images to a floating point numpy array for augmentation\n",
    "imgs_pxl_array = np.array(images).astype('float32')\n",
    "\n",
    "# Since pixel values are ranging from 0-255, normaize it by dividing by 255\n",
    "normalized_images = [img / 255 for img in imgs_pxl_array]\n",
    "\n",
    "# Print out the first image values\n",
    "print(normalized_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an image augmentation pipeline\n",
    "image_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomRotation(0.05),        # Random rotation (18 degrees)\n",
    "    tf.keras.layers.RandomZoom(0.25),            # Random zoom\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\")    # Random horizontal flip\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels and prepare X and y\n",
    "\n",
    "y_encoder = LabelEncoder().fit(labels)\n",
    "y = y_encoder.transform(labels)\n",
    "\n",
    "X = np.array(normalized_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets with 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list for X and y augmentations\n",
    "X_train_aug = []\n",
    "y_train_aug = []\n",
    "\n",
    "# Loop through the entire X_train set\n",
    "for i in range(len(X_train)):\n",
    "    # Select the original image and its y label\n",
    "    img = X_train[i]\n",
    "    label = y_train[i]\n",
    "\n",
    "    # Ensure that the input data has the correct shape\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Add one more augmented for every original\n",
    "    # Create and append the image\n",
    "    X_train_aug.append(image_augmentation(img, training=True)[0].numpy())\n",
    "    # Append the original label\n",
    "    y_train_aug.append(label)\n",
    "\n",
    "# Print the length of the augmented images and the labels\n",
    "print(len(X_train_aug))\n",
    "print(len(y_train_aug))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the original and augmented images and labels\n",
    "X_train = np.concatenate((X_train, np.array(X_train_aug)))\n",
    "y_train = np.concatenate((y_train, np.array(y_train_aug)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set ulimit to 12G to deal with large data export\n",
    "!ulimit -n 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the augmented images and labels in pickle files\n",
    "pickle.dump(y_train, \n",
    "            open(\"../../pickles/y_train_aug.pkl\", \"wb\"), \n",
    "            protocol=pickle.HIGHEST_PROTOCOL)\n",
    "pickle.dump(X_train, \n",
    "            open(\"../../pickles/X_train_aug.pkl\", \"wb\"), \n",
    "            protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export test images and labels in pickle files\n",
    "pickle.dump(y_test, \n",
    "            open(\"../../pickles/y_test.pkl\", \"wb\"), \n",
    "            protocol=pickle.HIGHEST_PROTOCOL)\n",
    "pickle.dump(X_test, \n",
    "            open(\"../../pickles/X_test.pkl\", \"wb\"), \n",
    "            protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
